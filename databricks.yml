# This is a Databricks asset bundle definition for marvelous-databricks-course-jooaobrum.
# The Databricks extension requires databricks.yml configuration file.
# See https://docs.databricks.com/dev-tools/bundles/index.html for documentation.

bundle:
  name: marvelous-databricks-course-jooaobrum

include:
  - bundle_monitoring.yml

artifacts:
  default:
    type: whl
    build: uv build
    path: .

variables:
  git-sha:
    description: git-sha
    default: abcd
  branch:
    description: branch
    default: main
  schedule_pause_status:
    description: schedule pause status
    default: UNPAUSED


resources:
  jobs:
    hotel-reservation:
      name: hotel-reservation-workflow-test-demo
      schedule:
        quartz_cron_expression: "0 0 6 ? * MON"
        timezone_id: "Europe/Amsterdam"
        pause_status: ${var.schedule_pause_status}
      tags:
        project_name: "hotel-reservation"

      tasks:
        - task_key: "preprocessing"
          existing_cluster_id: 0201-105915-sb4m34sp
          spark_python_task:
            python_file: "scripts/01_data_processing.py"
            parameters:
              - "--root_path"
              - ${workspace.root_path}
              - "--env"
              - ${bundle.target}
          libraries:
           - whl: ./dist/*.whl
        - task_key: "train_model"
          existing_cluster_id: 0201-105915-sb4m34sp
          depends_on:
            - task_key: "preprocessing"
          spark_python_task:
            python_file: "scripts/02_train_and_register_fe_model.py"
            parameters:
              - "--root_path"
              - ${workspace.root_path}
              - "--env"
              - ${bundle.target}
              - "--git-sha"
              - ${var.git-sha}
              - "--job_run_id"
              - "{{job.id}}"
              - "--branch"
              - ${var.branch}
          libraries:
            - whl: ./dist/*.whl
        - task_key: model_updated
          condition_task:
            op: "EQUAL_TO"
            left: "{{tasks.train_model.values.model_updated}}"
            right: "1"
          depends_on:
            - task_key: "train_model"
        - task_key: "deploy_model"
          depends_on:
            - task_key: "model_updated"
              outcome: "true"
          existing_cluster_id: 0201-105915-sb4m34sp
          spark_python_task:
            python_file: "scripts/03_deploy_fe_model_serving_endpoint.py"
            parameters:
              - "--root_path"
              - ${workspace.root_path}
              - "--env"
              - ${bundle.target}
          libraries:
            - whl: ./dist/*.whl

targets:
  dev:
    cluster_id: 0201-105915-sb4m34sp
    default: true
    mode: development
    workspace:
      host: https://adb-2625093468221227.7.azuredatabricks.net
      root_path: /Workspace/Users/${workspace.current_user.userName}/.bundle/${bundle.target}/${bundle.name}



  ## Optionally, there could be 'staging' or 'prod' targets here.
  #
  # prod:
  #   workspace:
  #     host: https://adb-2625093468221227.7.azuredatabricks.net
